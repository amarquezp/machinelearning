---
title: "Practical Machine Learning - Course Project"
author: "Antonio Marquez Palacios"
date: "March 4, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE}
library(caret)
setwd("C:/datascience/practical machine learning/")
```
## Loading and setting the data

Data for this project can be found

Training data set: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
Testing data set: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

An initial exploratory analysis reveals some columns have NA/NULL/empty values in their majority observations; also the data is not dependent on time, so  will remove them to have a cleaner analysis

```{r echo=TRUE}
# Load the set Data Set
set.seed(33878)
trainingFilePath  <- "pml-training.csv"
testingFilePath   <- "pml-testing.csv"

pmlTrainDS        <- read.csv(trainingFilePath)
pmlTestDS         <- read.csv(testingFilePath)

validColumns      <- c(2, 6:11, 37:49, 60:68, 84:86, 102, 113:124,140,151:160 )
# Remove those columns that have NA in their majority observations
filteredTrainDS   <- pmlTrainDS[, validColumns]
filteredTestDS    <- pmlTestDS[, validColumns]

# Set a value to be the outcome of the models:
inTrain   <- createDataPartition(filteredTrainDS$classe, p=0.7, list=FALSE)
training  <- filteredTrainDS[inTrain, ]
testing   <- filteredTrainDS[-inTrain,]

totalCol <- which(grepl("^total", names(training), ignore.case=FALSE))

featurePlot(x= training[, totalCol], y=training$classe, pch=19, plot="pairs")
```

## Fitting a Model and Cross Validation
Random Forest is the selected model because of its accuracy. Calculating Random Forest will take some time.
We will use Cross-Validation algorithm included in caret package.

```{r echo=TRUE}

modRf   <- train(classe ~ ., method="rf", trControl=trainControl(method="cv", number=4), data=training)
plot(modRf, xlab="predictors", main="Random Forest Model")

predRf  <- predict(modRf, testing)
summary(predRf)

# Accuracy:
accuracy      <- modRf$results[3,2]

# Out Of Sample Error:
ooSampleError <- 1 - accuracy

data.frame(accuracy=accuracy, OutSampleError=ooSampleError)

```




